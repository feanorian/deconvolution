{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b710ee7c-81c3-4a55-b262-6d6ea7be965d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPT0205',\n",
       " 'SPT0546',\n",
       " 'SPT2106',\n",
       " 'SpARCS0035',\n",
       " 'SpARCS0219',\n",
       " 'SpARCS0335',\n",
       " 'SpARCS1034',\n",
       " 'SpARCS1051',\n",
       " 'SpARCS1616',\n",
       " 'SpARCS1634',\n",
       " 'SpARCS1638']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "#astropy imports\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.nddata import NDData\n",
    "import ast\n",
    "from astropy.nddata import StdDevUncertainty\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.table import Table, Column\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.wcs import WCS\n",
    "from photutils.detection import find_peaks\n",
    "from astropy.nddata.utils import Cutout2D\n",
    "from photutils.background import MMMBackground\n",
    "from photutils.psf import extract_stars\n",
    "# photutils imports\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils.psf import PSFPhotometry, SourceGrouper, IntegratedGaussianPRF, extract_stars, EPSFBuilder, EPSFStar\n",
    "# my modules\n",
    "from cat_match import create_skycoord\n",
    "from psf_gen import return_filtered_table, build_psf_from_catalog, save_psf_to_fits\n",
    "\n",
    "os_check = platform.platform(terse=True)[:5]\n",
    "\n",
    "if os_check == 'macOS':\n",
    "    preamble = '/path/to/mac/'\n",
    "    root2 = f'{preamble}Deconvolution/'\n",
    "    root1 = f'{root2}Data/PHOTOMETRY/PHOTOM_CATS/'\n",
    "else:\n",
    "    preamble = '/path/to/linux/'\n",
    "    root2 = f'{preamble}Deconvolution/'\n",
    "    root1 = f'{root2}Data/PHOTOMETRY/PHOTOM_CATS/'\n",
    "\n",
    "psf_dir = f'{root2}PSFs/'    \n",
    "test_dir = f'{root2}test_dir'\n",
    "\n",
    "cluster_images = pd.read_csv('final_file_merge_w_psf.csv') \n",
    "cluster_images = pd.read_csv('psfm_final_merge.csv') \n",
    "#cluster_images.iloc[18:20]['Band']\n",
    "clusters = cluster_images['Cluster'].unique()\n",
    "remove_clust = [ 'SpARCS0034', 'SpARCS0036','SpARCS0215', 'SpARCS1047', 'SpARCS1613']\n",
    "clusters = [x for x in clusters if x not in remove_clust]\n",
    "plot_dir = f'{root2}Plots'\n",
    "star_cut_cats_dir = f'{root2}star_cut_catalogs'\n",
    "#cluster_df_2 = pd.read_csv('final_merge.csv')\n",
    "cluster_df_2 = cluster_images\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a819f489-1667-4059-8579-3168bd671ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cutouts(cluster, band, catalog_file, data_file, noise_file, in_cluster = False):\n",
    "    \"\"\"\n",
    "\tBuild a PSF using stars from a catalog by extracting RA/Dec, converting to pixels,\n",
    "\tand using EPSFBuilder.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- cluster: The cluster name\n",
    "\t- band: The band of the image\n",
    "\t- fits_file: Path to the FITS file containing image data\n",
    "\t- catalog_file: Path to the catalog (CSV or similar) containing RA and Dec columns\n",
    "\t- ra_col: Name of the column containing RA values in the catalog\n",
    "\t- dec_col: Name of the column containing Dec values in the catalog\n",
    "\t- size: Size of the cutout box for stars (default is 33x33 pixels)\n",
    "\t- threshold: Detection threshold for find_peaks (default is 500.0)\n",
    "\t\n",
    "\tReturns:\n",
    "\t- epsf: The built effective PSF object\n",
    "\t\"\"\"\n",
    "\t# Load the image data from the FITS file\n",
    "    size = (32,32)\n",
    "    main_dir = '/home/six6ix6ix/OneDrive_brooksc99@ku.edu/Deconvolution/'\n",
    "    #main_dir = '/home/six6ix6ix/OneDrive_brooksc99@ku.edu/Deconvolution/test_dir/'\n",
    "    with fits.open(data_file) as hdu_d:\n",
    "        image_data = hdu_d[0].data\n",
    "        image_header = hdu_d[0].header\n",
    "        wcs = WCS(image_header)\n",
    "        \n",
    "      # Load the noise data from the FITS file\n",
    "    with fits.open(noise_file) as hdu_n:\n",
    "        noise_data = hdu_n[0].data\n",
    "        noise_header = hdu_n[0].header\n",
    "    # Load the catalog data (assuming it's a CSV; adjust this if using a different format)\n",
    "    catalog = pd.read_csv(catalog_file)\n",
    "    \n",
    "    cid_m,cluster_m, zspec_m,zq_spec,M,D4000,eD4000,BIC,member,zcluster,UVspec,VJspec, NUVMINV, specid_m,zphot_m,Star_m,K_flag_m = catalog[['cluster_id','Cluster' ,'Redshift','Redshift_Quality','Mstellar','D4000','eD4000','delta_BIC','member','Redshift_c','UMINV','VMINJ','NUVMINV','SPECID','zphot','Star','K_flag_x']].values.T\n",
    "    select_s = np.where((Star_m == 1) & (cluster_m == f'{cluster}'))\n",
    "    \n",
    "    \n",
    "    galaxy_catalog = catalog.iloc[select_g]\n",
    "    star_catalog = catalog.iloc[select_s]\n",
    "    coords = [(np.array(ra), np.array(dec)) for ra, dec in zip(galaxy_catalog['ra_x'], galaxy_catalog['dec_x'])]\n",
    "\n",
    "    for i in range(len(galaxy_catalog)):\n",
    "        gal_id = galaxy_catalog.iloc[i]['cPHOTID']\n",
    "        position = SkyCoord(coords[i][0], coords[i][1], unit=(u.deg, u.deg), frame='icrs')\n",
    "        \n",
    "        # Data cutout\n",
    "        cutout_data =  Cutout2D(image_data, position,  size, wcs=wcs)\n",
    "        # Noise cutouts\n",
    "        cutout_noise = Cutout2D(noise_data, position, size, wcs=wcs)\n",
    "        \n",
    "        #hdud = fits.PrimaryHDU(cutout_data, header=image_header)\n",
    "        #hdun = fits.PrimaryHDU(cutout_noise, header=noise_header)\n",
    "\n",
    "        hdud = fits.PrimaryHDU(cutout_data.data, header=image_header)\n",
    "        hdun = fits.PrimaryHDU(cutout_noise.data, header=noise_header)\n",
    "        \n",
    "        data_cutout_filename = f'{cluster}_{band}_{gal_id}_data.fits'\n",
    "        noise_cutout_filename = f'{cluster}_{band}_{gal_id}_noise.fits'\n",
    "    \n",
    "        data_cutout_path = f'{main_dir}{cluster}/{band}/data_cutouts/'\n",
    "        noise_cutout_path =  f'{main_dir}{cluster}/{band}/noise_cutouts/'\n",
    "\n",
    "        #os.makedirs(data_cutout_path, exist_ok=True)\n",
    "        #os.makedirs(noise_cutout_path, exist_ok=True)\n",
    "        \n",
    "        data_cutout = os.path.join(data_cutout_path,data_cutout_filename)\n",
    "        noise_cutout = os.path.join(noise_cutout_path,noise_cutout_filename)\n",
    "\n",
    "        hdud.writeto(data_cutout, overwrite=True)\n",
    "        hdun.writeto(noise_cutout, overwrite=True)\n",
    "    \n",
    "        fits.setval(data_cutout, 'CRVAL1', value = galaxy_catalog.iloc[i]['ra_x'])\n",
    "        fits.setval(data_cutout, 'CRVAL2', value = galaxy_catalog.iloc[i]['dec_x'])\n",
    "        fits.setval(data_cutout, 'CRPIX1', value = size[0])\n",
    "        fits.setval(data_cutout, 'CRPIX2', value = size[0])\n",
    "        \n",
    "        fits.setval(noise_cutout, 'CRVAL1', value = galaxy_catalog.iloc[i]['ra_x'])\n",
    "        fits.setval(noise_cutout, 'CRVAL2', value = galaxy_catalog.iloc[i]['dec_x'])\n",
    "        fits.setval(noise_cutout, 'CRPIX1', value = size[0])\n",
    "        fits.setval(noise_cutout, 'CRPIX2', value = size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf54f11-8e94-4d01-8867-67cede5722c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cutouts_psfm(cluster, band, catalog_file, data_file):\n",
    "    \"\"\"\n",
    "\tBuild a PSF using stars from a catalog by extracting RA/Dec, converting to pixels,\n",
    "\tand using EPSFBuilder.\n",
    "\t\n",
    "\tParameters:\n",
    "\t- cluster: The cluster name\n",
    "\t- band: The band of the image\n",
    "\t- fits_file: Path to the FITS file containing image data\n",
    "\t- catalog_file: Path to the catalog (CSV or similar) containing RA and Dec columns\n",
    "\t- ra_col: Name of the column containing RA values in the catalog\n",
    "\t- dec_col: Name of the column containing Dec values in the catalog\n",
    "\t- size: Size of the cutout box for stars (default is 33x33 pixels)\n",
    "\t- threshold: Detection threshold for find_peaks (default is 500.0)\n",
    "\t\n",
    "\tReturns:\n",
    "\t- epsf: The built effective PSF object\n",
    "\t\"\"\"\n",
    "\t# Load the image data from the FITS file\n",
    "    size = (32,32)\n",
    "    main_dir = f'{root2}Deconvolution/'\n",
    " \n",
    "    with fits.open(data_file) as hdu_d:\n",
    "        image_data = hdu_d[0].data\n",
    "        image_header = hdu_d[0].header\n",
    "        wcs = WCS(image_header)\n",
    "        \n",
    "   \n",
    "    # Load the catalog data (assuming it's a CSV; adjust this if using a different format)\n",
    "    catalog = pd.read_csv(catalog_file)\n",
    "    \n",
    "    cid_m,cluster_m, zspec_m,zq_spec,M,D4000,eD4000,BIC,member,zcluster,UVspec,VJspec, NUVMINV, specid_m,zphot_m,Star_m,K_flag_m = catalog[['cluster_id','Cluster' ,'Redshift','Redshift_Quality','Mstellar','D4000','eD4000','delta_BIC','member','Redshift_c','UMINV','VMINJ','NUVMINV','SPECID','zphot','Star','K_flag_x']].values.T\n",
    "    select_s = np.where((Star_m == 1) & (cluster_m == f'{cluster}'))\n",
    "    select_g = np.where((Star_m == 0) & (cluster_m == f'{cluster}'))\n",
    "    \n",
    "    galaxy_catalog = catalog.iloc[select_g]\n",
    "    star_catalog = catalog.iloc[select_s]\n",
    "    coords = [(np.array(ra), np.array(dec)) for ra, dec in zip(galaxy_catalog['ra_x'], galaxy_catalog['dec_x'])]\n",
    "\n",
    "    for i in range(len(galaxy_catalog)):\n",
    "        gal_id = galaxy_catalog.iloc[i]['cPHOTID']\n",
    "        position = SkyCoord(coords[i][0], coords[i][1], unit=(u.deg, u.deg), frame='icrs')\n",
    "        \n",
    "        # Data cutout\n",
    "        cutout_data =  Cutout2D(image_data, position,  size, wcs=wcs)\n",
    "     \n",
    "\n",
    "        hdud = fits.PrimaryHDU(cutout_data.data, header=image_header)\n",
    "        \n",
    "        \n",
    "        data_cutout_filename = f'{cluster}_{band}_{gal_id}_psf_data_cutouts.fits'\n",
    "        \n",
    "    \n",
    "        data_cutout_path = f'{main_dir}{cluster}/{band}/psf_matched_fits/'\n",
    "        \n",
    "\n",
    "        #os.makedirs(data_cutout_path, exist_ok=True)\n",
    "        #os.makedirs(noise_cutout_path, exist_ok=True)\n",
    "        \n",
    "        data_cutout = os.path.join(data_cutout_path,data_cutout_filename)\n",
    "        \n",
    "\n",
    "        hdud.writeto(data_cutout, overwrite=True)\n",
    "        \n",
    "    \n",
    "        fits.setval(data_cutout, 'CRVAL1', value = galaxy_catalog.iloc[i]['ra_x'])\n",
    "        fits.setval(data_cutout, 'CRVAL2', value = galaxy_catalog.iloc[i]['dec_x'])\n",
    "        fits.setval(data_cutout, 'CRPIX1', value = size[0])\n",
    "        fits.setval(data_cutout, 'CRPIX2', value = size[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88e841b4-9a68-4a08-9e02-1be0ebd68690",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9226012-59fd-40c6-821e-7c2e162bf98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set DATE-OBS to '2018-10-18' from MJD-OBS'. [astropy.wcs.wcs]\n"
     ]
    }
   ],
   "source": [
    "for cluster in clusters:\n",
    "\n",
    "    file = f'{root2}merged_catalogs/{cluster}_gg_sextractor_merged.csv'\n",
    "    cluster_df = pd.read_csv(file)\n",
    "    #cluster_df_2 = pd.read_csv(files_bands_list)\n",
    "    #filtered_df = cluster_df_2[cluster_df_2['Cluster'] == cluster]\n",
    "    \n",
    "    filtered_df = cluster_df_2[(cluster_df_2['Cluster'] == cluster) & (cluster_df_2['Band'] == 'FOURSTARJ')]\n",
    "\n",
    "    #band_list = list(filtered_df['Band'])\n",
    "    \n",
    "    for i in filtered_df.index:\n",
    "        #data = filtered_df['PSFM Data File'][i]\n",
    "        data = filtered_df['Data File'][i]\n",
    "        noise = filtered_df['Noise File'][i]\n",
    "        band = filtered_df['Band'][i]\n",
    "        #print(filtered_df['Cluster'][i], cluster_df,filtered_df['Band'][i], filtered_df['Data File'][i], filtered_df['Noise File'][i])\n",
    "        make_cutouts(cluster, band, file, data, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a0282-63ca-4c8e-83c0-f6de1d5857bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "total_time = (t1 - t0)/60\n",
    "print(f'Total time: {total_time} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9343c37-0739-4acb-b633-859f9bcdd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "\n",
    "    file = f'{root2}merged_catalogs/{cluster}_gg_sextractor_merged.csv'\n",
    "    cluster_df = pd.read_csv(file)\n",
    "    #cluster_df_2 = pd.read_csv(files_bands_list)\n",
    "    #filtered_df = cluster_df_2[cluster_df_2['Cluster'] == cluster]\n",
    "    \n",
    "    filtered_df = cluster_df_2[(cluster_df_2['Cluster'] == cluster) & (cluster_df_2['Band'] == 'FOURSTARJ')]\n",
    "\n",
    "    #band_list = list(filtered_df['Band'])\n",
    "    \n",
    "    for i in filtered_df.index:\n",
    "        data = filtered_df['PSFM Data File'][i]\n",
    "        data = filtered_df['PSFM Data File'][i]\n",
    "        #noise = filtered_df['Noise File'][i]\n",
    "        band = filtered_df['Band'][i]\n",
    "        #print(filtered_df['Cluster'][i], cluster_df,filtered_df['Band'][i], filtered_df['Data File'][i], filtered_df['Noise File'][i])\n",
    "        make_cutouts_psfm(cluster, band, file, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75a216-7d27-4574-b811-3c8e6692768d",
   "metadata": {},
   "source": [
    "# HST Cutouts (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e36258-86e6-4074-b291-7a81e020f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from astropy.nddata import Cutout2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_common_footprint(fits_files):\n",
    "    \"\"\"\n",
    "    Find the common footprint of multiple FITS images by intersecting their WCS bounds.\n",
    "    \"\"\"\n",
    "    footprints = []\n",
    "    \n",
    "    for file in fits_files:\n",
    "        with fits.open(file) as hdul:\n",
    "            wcs = WCS(hdul[0].header)\n",
    "            ny, nx = hdul[0].data.shape\n",
    "            corners = SkyCoord.from_pixel([0, 0, nx-1, nx-1], [0, ny-1, 0, ny-1], wcs)\n",
    "            footprints.append(corners)\n",
    "    \n",
    "    # Intersect footprint regions (bounding RA and DEC ranges)\n",
    "    ra_min = max([fp.ra.min().deg for fp in footprints])\n",
    "    ra_max = min([fp.ra.max().deg for fp in footprints])\n",
    "    dec_min = max([fp.dec.min().deg for fp in footprints])\n",
    "    dec_max = min([fp.dec.max().deg for fp in footprints])\n",
    "    \n",
    "    return ra_min, ra_max, dec_min, dec_max\n",
    "\n",
    "def filter_coordinates_in_footprint(ra_min, ra_max, dec_min, dec_max, coords_df):\n",
    "    \"\"\"\n",
    "    Filter coordinates that lie within the common footprint.\n",
    "    \"\"\"\n",
    "    filtered_coords = coords_df[(coords_df['ra'] >= ra_min) & (coords_df['ra'] <= ra_max) & \n",
    "                                (coords_df['dec'] >= dec_min) & (coords_df['dec'] <= dec_max)]\n",
    "    return filtered_coords\n",
    "\n",
    "def create_cutouts(fits_files, filtered_coords, cutout_size=(50, 50)):\n",
    "    \"\"\"\n",
    "    Create cutouts for each coordinate in the filtered list within each FITS file.\n",
    "    \"\"\"\n",
    "    cutouts_dict = {f\"cutouts_band_{i+1}\": [] for i in range(len(fits_files))}\n",
    "    \n",
    "    for i, file in enumerate(fits_files):\n",
    "        with fits.open(file) as hdul:\n",
    "            wcs = WCS(hdul[0].header)\n",
    "            for _, row in filtered_coords.iterrows():\n",
    "                position = SkyCoord(ra=row['ra'], dec=row['dec'], unit='deg')\n",
    "                cutout = Cutout2D(hdul[0].data, position, cutout_size, wcs=wcs)\n",
    "                cutouts_dict[f\"cutouts_band_{i+1}\"].append(cutout.data)\n",
    "    \n",
    "    return cutouts_dict\n",
    "\n",
    "# Example usage:\n",
    "# Assuming coords_df is a DataFrame with 'ra' and 'dec' columns\n",
    "fits_files = ['file1.fits', 'file2.fits', 'file3.fits']\n",
    "coords_df = pd.DataFrame({'ra': [150.0, 151.2, 149.8], 'dec': [2.3, 2.5, 2.1]})\n",
    "\n",
    "# Step 1: Find common footprint\n",
    "ra_min, ra_max, dec_min, dec_max = find_common_footprint(fits_files)\n",
    "\n",
    "# Step 2: Filter coordinates within the common footprint\n",
    "filtered_coords = filter_coordinates_in_footprint(ra_min, ra_max, dec_min, dec_max, coords_df)\n",
    "\n",
    "# Step 3: Create cutouts\n",
    "cutouts_dict = create_cutouts(fits_files, filtered_coords)\n",
    "\n",
    "# Converting filtered_coords to an Astropy table to return\n",
    "filtered_table = Table.from_pandas(filtered_coords)\n",
    "print(filtered_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e7827-4dff-49ab-af4b-8cefba145a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea37033-257a-4eae-b8a7-3766cfd91de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87f788-bb3c-4c1a-bf00-8b5b6e733f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6064f214-b527-4db9-acb4-3c55a6594884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440daf94-7a47-4787-a357-adbc85e7123d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae459b4-c4cd-403e-b06d-2419a45dfb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd2024-307c-4a41-a7ec-69542585e880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581a754-531f-47a5-8a6f-fc3e74f96db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c44ae7-e834-4265-a53c-671db5f4d3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c0a84-fb69-4c29-b4c6-070c53614216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4575d4cf-6c90-4479-abfa-195cd08adc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ef7b9-97a5-4ae5-84b2-360373862891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64425f3a-1e62-490f-9e08-d937d044f5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320fbc7-0f3d-4c1a-8667-2a86d07ca2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984e306-f22a-447b-9a41-2dcfd737f7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961e353-543d-4cd8-9a28-1709311ecbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d12ad-669d-4baa-98dd-076dc5ccb7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
