{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c58e35-0a0b-43c9-bfa1-c3e4f91be7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deconv_sunet import deconv_sunet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import glob\n",
    "import os\n",
    "import platform\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from matplotlib import colors\n",
    "import pandas as pd\n",
    "from astropy.io import ascii,fits\n",
    "from astropy.table import Table\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a71435-76de-4db6-8a50-64b0cd799c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_check = platform.platform(terse=True)[:5]\n",
    "if os_check == 'macOS':\n",
    "    preamble = '/path/to/mac/'\n",
    "    root2 = f'{preamble}Deconvolution/'\n",
    "    root1 = f'{root2}Data/PHOTOMETRY/PHOTOM_CATS/'\n",
    "else:\n",
    "    preamble = '/path/to/linux/'\n",
    "    root2 = f'{preamble}Deconvolution/'\n",
    "    root1 = f'{root2}Data/PHOTOMETRY/PHOTOM_CATS/'\n",
    "\n",
    "final_files_bands = f'{root2}psfm_final_merge.csv'\n",
    "\n",
    "psf_dir = f'{root1}PSFs/'    \n",
    "test_dir = f'{root1}test_dir'\n",
    "\n",
    "SUNet_path = f'path/to/SUNet'             # Path to SUNet repository\n",
    "model_dir = f'{SUNet_path}checkpoints/'     # Path to SUNet model directory\n",
    "model_name = 'SUNet_model_bestSSIM_ep-400_bs-16_ps-1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68aaec4-f7ef-4c8a-be98-e4ba0e2e2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = pd.read_csv(final_files_bands)\n",
    "clusters = cluster_df['Cluster'].unique()\n",
    "remove_clust = [ 'SpARCS0034', 'SpARCS0036','SpARCS0215', 'SpARCS1047', 'SpARCS1613']\n",
    "clusters = [x for x in clusters if x not in remove_clust]\n",
    "irac = ['IRAC1', 'IRAC2', 'IRAC3', 'IRAC4']\n",
    "cluster_df = cluster_df[~cluster_df['Band'].isin(irac) ]\n",
    "plot_dir = f'{root2}Plots'\n",
    "star_cut_cats_dir = f'{root2}star_cut_catalogs'\n",
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d1c11-5462-4ed8-90b6-fcc682f133b2",
   "metadata": {},
   "source": [
    "# Deconvolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf7909-17e2-4e62-9358-e76c950b4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decon(cluster, band, files, psf):\n",
    "    #for i in range(len(j_file_paths)):\n",
    "    \n",
    "    for i in range(len(files)):\n",
    "    #for i in range(1):\n",
    "        file_id = files[i][-19:-10]\n",
    "        hdu = fits.open(files[i])[0]\n",
    "        image = np.array(hdu.data)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        #hst = fits.open(hst_data[i])[0]\n",
    "        psf = psf_data_j / np.sum(psf_data_j)\n",
    "        \"\"\"    \n",
    "        Convention :\n",
    "        \n",
    "            Input Ground-based noisy Image(s)   : 4D numpy array  (number of samples, channels, height, width).\n",
    "                \n",
    "        \"\"\"\n",
    "        \n",
    "        #vlt = np.load('Data/vlt.npy')\n",
    "        #vlt = np.array([np.load(file) for file in file_paths])[0]\n",
    "        \n",
    "        #print('Dimensions =', Ks.shape)\n",
    "        #cmap = 'RdBu_r\n",
    "    \n",
    "    \n",
    "        \"\"\"\n",
    "        Run the SUNet deconvolution\n",
    "        Replace the input paths with the path to your cloned SUNet repository and the path to your SUNet model directory.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Factor by which the PSF is oversampled with respect to the noisy image\n",
    "        # Deconvolved ouput will have the same dimensions as the PSF\n",
    "        sampling_factor = psfs.shape[2]//image.shape[2]     \n",
    "        \n",
    "        # Run the SUNet deconvolution\n",
    "        deconv_result, _ = deconv_sunet(image, \n",
    "                                        psf, \n",
    "                                        sampling_factor = sampling_factor,                       # Sampling factor\n",
    "                                        SUNet_path= f'{preamble}SUNet/' ,                # Path to SUNet repository\n",
    "                                        model_dir = f'{SUNet_path}checkpoints/', \n",
    "                                        model_name = 'new_model_bestSSIM_ep-400_bs-16_ps-1.pth')    # Path to SUNet model directory\n",
    "                                                 # Name of the pre-trained SUNet model)\n",
    "        \n",
    "        deconv_result.shape             # Shape = (vlt.shape[0], vlt.shape[1], vlt.shape[2]*sampling_factor, vlt.shape[3]*sampling_factor)\n",
    "        hdu_decon = fits.PrimaryHDU(deconv_result)\n",
    "        #hdu_decon.writeto(f'{root2}/{cluster}/{band}/deconvolved_fits/{cluster}_{band}_{file_id}_cutout_{label}.fits', overwrite=True)\n",
    "        hdu_decon.writeto(f'{root2}/{cluster}/{band}/deconvolved_fits/{cluster}_{band}_{file_id}_cutout_decon.fits', overwrite=True)\n",
    "\n",
    "def decon_test(cluster, band, files, psf):\n",
    "    \n",
    "       \n",
    "    for i in range(len(files)):\n",
    "        file_id = files[i][-19:-10]\n",
    "        \n",
    "        # Open the file using the context manager\n",
    "        with fits.open(files[i]) as hdu_list:\n",
    "            hdu = hdu_list[0]\n",
    "            image = np.array(hdu.data)\n",
    "\n",
    "            if image.shape != (32, 32):\n",
    "                print(f\"Skipping file {files[i]} due to incompatible shape: {image.shape}\")\n",
    "                continue  # Skip this file and proceed to the next\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "     \n",
    "        # Factor by which the PSF is oversampled with respect to the noisy image\n",
    "        # Use the last dimension of the PSF and the image to calculate sampling_factor\n",
    "        sampling_factor = psf.shape[2] // image.shape[2]  # Use -1 to access the last dimension safely\n",
    "        \n",
    "        # Run the SUNet deconvolution\n",
    "        deconv_result, _ = deconv_sunet(image, \n",
    "                                        psf, \n",
    "                                        sampling_factor=sampling_factor,           # Sampling factor\n",
    "                                        SUNet_path=f'{preamble}SUNet/',            # Path to SUNet repository\n",
    "                                        model_dir=f'{SUNet_path}checkpoints/', \n",
    "                                        model_name='new_model_bestSSIM_ep-400_bs-16_ps-1.pth')  # SUNet model\n",
    "\n",
    "        # Save the deconvolved result as a new FITS file\n",
    "        hdu_decon = fits.PrimaryHDU(deconv_result)\n",
    "        hdu_decon.writeto(f'{root2}/{cluster}/{band}/deconvolved_fits/{cluster}_{band}_{file_id}_cutout_decon.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a2907-8516-49fd-8e85-deb0617d6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a snippet to change the file prefixes depending on the plaftorm\n",
    "def change_to_mac_prefix(filename):\n",
    "    prefix = '/home/six6ix6ix/OneDrive_brooksc99@ku.edu/Deconvolution/'\n",
    "    new_prefix = '/Users/lordereinion/OneDrive - University of Kansas/Deconvolution/'\n",
    "        \n",
    "    if os_check == 'macOS':\n",
    "        if filename.startswith(prefix):\n",
    "            filename = filename.replace(prefix, new_prefix, 1)\n",
    "            #print(cluster, filename)\n",
    "            return filename\n",
    "    else:\n",
    "        filename = filename.replace(prefix,\" \", 1)\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e7486-ceda-48b2-a4a7-8d593c7edb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a84741e5-2e25-4612-8ae5-f75532c1ef88",
   "metadata": {},
   "source": [
    "# Execute Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02750e-9e30-4618-8b85-749d8880353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    filtered_df = cluster_df[(cluster_df['Cluster'] == cluster) & (cluster_df['Band'] == 'VIMOSz')]\n",
    "    for i in filtered_df.index:\n",
    "        band = filtered_df['Band'][i]\n",
    "        #data_file = filtered_df['Data File'][i]\n",
    "        #noise_file = filtered_df['Noise File'][i]\n",
    "        psf_file = [filtered_df['PSF File'][i]]\n",
    "        galaxy_files_dir = f'{root2}{cluster}/{band}/data_cutouts/'\n",
    "        galaxy_files = sorted(glob.glob(os.path.join(galaxy_files_dir, '*.fits')))\n",
    "        #file_1 = decon_test(cluster, band, galaxy_files, psf_file)\n",
    "        psf_data = np.array([fits.getdata(file, header=False) for file in psf_file])\n",
    "        psf = psf_data / np.sum(psf_data)\n",
    "        decon_test(cluster, band, galaxy_files, psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4843f-783b-4c45-86d4-e2174a225899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d9858-bfcd-4243-afff-c8e624824836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e861e0-531f-4b22-af25-fc16d2dda681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b8127-ef04-4dcf-b85f-fe8ec82dadca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57024fec-e81f-4e75-8d01-15633278a1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5f52a-154c-4f59-95c6-fc0f42160231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0751c-ba54-464c-845c-8efb2d240649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5f6fd-412c-4889-9ef4-52c61b377b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e96900-16e8-4699-a85f-bb52c4653886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad39d64-27f9-4394-aff4-b3e782f8b806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84248d10-4ad3-4756-8230-f36920b709b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa0a48-0f24-4e5f-a4bb-700b1f2d1e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb25421-d45b-4920-9e28-0af8907869c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c31e3-920f-4046-a102-afe91dbca86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc913472-ce77-4871-8086-6896d2c6b5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab305054-ae7e-4b4b-a19d-a066aa8b7926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db3ce4-afd5-476d-bc4b-2d15bf03f359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f53030-1125-45ca-b1ca-583776b6e74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5164e-2c83-43ee-9a62-ea96f819f84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be36606-2445-44d3-b994-e0ef91095f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d2fcc7-a203-4c83-b1fb-37802a75cddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
